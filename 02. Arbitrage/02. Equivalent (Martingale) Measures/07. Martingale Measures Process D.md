## Densidades Condicionais de Um Passo e a Construção de Medidas Martingale Equivalentes

### Introdução

Como estabelecido anteriormente pelo Teorema Fundamental da Precificação de Ativos (FTAP) em sua forma mais simples (Teorema 2.1), as **medidas martingale equivalentes (EMMs)** desempenham um papel central na finança matemática, particularmente na ausência de arbitragem [^8.1, ^9.1]. A existência de uma EMM $Q$ equivalente à medida de probabilidade original $P$ ($Q \approx P$) está intrinsecamente ligada à condição de não-arbitragem (NA) [^9.1]. Compreender a relação entre cálculos e propriedades probabilísticas sob $Q$ e $P$ é, portanto, fundamental [^14.1].

Neste capítulo, aprofundaremos a estrutura que conecta $P$ e $Q$ através do **processo de densidade** $Z$. Focaremos especificamente nos incrementos relativos deste processo, $D_k = Z_k/Z_{k-1}$, demonstrando como eles funcionam como **densidades condicionais de um passo** e como essa perspectiva facilita a análise e a construção explícita de EMMs em diversos cenários. Exploraremos a definição, propriedades e aplicação do processo $D = (D_k)_{k=1,...,T}$ na transformação de expectativas condicionais e na caracterização da propriedade martingale sob a medida $Q$.

### Conceitos Fundamentais

#### O Processo de Densidade Z e a Densidade D

Consideremos um espaço de probabilidade filtrado $(\Omega, \mathcal{F}, \mathbb{F} = (\mathcal{F}_k)_{k=0,...,T}, P)$ em tempo discreto finito. Seja $Q$ uma medida de probabilidade sobre $\mathcal{F}$ tal que $Q \approx P$ na $\sigma$-álgebra final $\mathcal{F}_T$. O teorema de Radon-Nikodým garante a existência de uma densidade $D = \frac{dQ}{dP}|_{\mathcal{F}_T}$, que é uma variável aleatória estritamente positiva $P$-q.s. (quase certamente sob $P$), tal que $Q[A] = E_P[D I_A]$ para todo $A \in \mathcal{F}_T$, e mais geralmente, $E_Q[Y] = E_P[YD]$ para qualquer variável aleatória $Y \ge 0$ [^14.2]. Note que $E_P[D] = E_Q[1] = 1$ [^14.2].

Para analisar a relação entre $P$ e $Q$ dinamicamente ao longo da filtração $\mathbb{F}$, introduzimos o **processo de densidade** $Z = (Z_k)_{k=0,...,T}$ (por vezes denotado $Z^Q$ ou $Z^{Q;P}$) definido por:
$$ Z_k := E_P[D | \mathcal{F}_k] $$
para $k=0, 1, ..., T$ [^14.3]. Por construção, $Z$ é um $P$-martingale adaptado à filtração $\mathbb{F}$. Como $D > 0$ $P$-q.s., segue-se das propriedades da esperança condicional que $Z_k > 0$ $P$-q.s. para todo $k$ [^14.4]. Assim, $Z$ é um P-martingale estritamente positivo [^15.2]. O valor $Z_k$ representa a densidade de $Q$ com respeito a $P$ restrita à $\sigma$-álgebra $\mathcal{F}_k$, ou seja, $Z_k = \frac{dQ}{dP}|_{\mathcal{F}_k}$ [^15.5]. Isso significa que para qualquer $A \in \mathcal{F}_k$ ou qualquer variável aleatória $Y$ $\mathcal{F}_k$-mensurável (positiva ou em $L^1(Q)$), temos $Q[A] = E_P[Z_k I_A]$ e $E_Q[Y] = E_P[Z_k Y]$ [^15.5]. É importante notar que, em geral, se $\mathcal{F}_T$ for estritamente maior que $\mathcal{F}$, então $Z_T \neq D$ [^15.5].

#### O Processo Dk como Razões de Densidades

Dado que o processo de densidade $Z$ é estritamente positivo $P$-q.s. [^15.2], podemos definir o processo $D = (D_k)_{k=1,...,T}$ através das razões dos seus valores sucessivos:

> **Definição:** O processo $D = (D_k)_{k=1,...,T}$ é definido por
> $$ D_k := \frac{Z_k}{Z_{k-1}} \quad \text{para } k = 1, \dots, T $$
> [^15.1]

Como $Z_k$ é $\mathcal{F}_k$-mensurável e $Z_{k-1}$ é $\mathcal{F}_{k-1}$-mensurável (e portanto $\mathcal{F}_k$-mensurável), $D_k$ é $\mathcal{F}_k$-mensurável. Logo, o processo $D$ é adaptado à filtração $\mathbb{F}$ [^15.3]. Além disso, como $Z_k > 0$ e $Z_{k-1} > 0$ $P$-q.s., temos que $D_k > 0$ $P$-q.s., tornando $D$ um processo estritamente positivo [^15.3].

Uma propriedade fundamental de $D_k$ decorre diretamente da propriedade de $P$-martingale de $Z$:
**Lema:** O processo $D = (D_k)_{k=1,...,T}$ satisfaz $E_P[D_k | \mathcal{F}_{k-1}] = 1$ para todo $k=1,...,T$.

**Prova:** Como $Z$ é um $P$-martingale, temos $E_P[Z_k | \mathcal{F}_{k-1}] = Z_{k-1}$. Uma vez que $Z_{k-1}$ é $\mathcal{F}_{k-1}$-mensurável e estritamente positivo, podemos escrever:
$$ E_P[D_k | \mathcal{F}_{k-1}] = E_P\left[ \frac{Z_k}{Z_{k-1}} \bigg| \mathcal{F}_{k-1} \right] = \frac{1}{Z_{k-1}} E_P[Z_k | \mathcal{F}_{k-1}] = \frac{1}{Z_{k-1}} Z_{k-1} = 1 \quad P\text{-q.s.} $$
[^15.4]. $\blacksquare$

#### Dk como Densidades Condicionais de Um Passo

A importância do processo $D_k$ reside na sua interpretação como densidade condicional local. A relação entre as esperanças condicionais sob $Q$ e $P$ é explicitada pela fórmula de Bayes (uma versão da qual é apresentada em [^15.5] como equação (3.2)). Especificamente, para $j=k-1$ e $U_k$ uma variável aleatória $\mathcal{F}_k$-mensurável (positiva ou em $L^1(Q)$), a fórmula (3.2) torna-se:

> **Fórmula de Bayes (Forma Local):**
> $$ E_Q[U_k | \mathcal{F}_{k-1}] = \frac{1}{Z_{k-1}} E_P[Z_k U_k | \mathcal{F}_{k-1}] = E_P\left[ \frac{Z_k}{Z_{k-1}} U_k \bigg| \mathcal{F}_{k-1} \right] = E_P[D_k U_k | \mathcal{F}_{k-1}] \quad Q\text{-q.s. (e } P\text{-q.s.)} $$
> (Equação (3.3) em [^16.3])

Esta fórmula é crucial: ela demonstra que $D_k$ atua como a **densidade condicional de um passo** (*one-step conditional density*) da medida $Q$ com respeito a $P$, relativamente à transição da informação de $\mathcal{F}_{k-1}$ para $\mathcal{F}_k$ [^16.4]. Essencialmente, para calcular a esperança condicional sob $Q$ de uma variável $\mathcal{F}_k$-mensurável, dada a informação em $\mathcal{F}_{k-1}$, podemos calcular a esperança condicional sob $P$, ponderando a variável por $D_k$.

Note também que o processo de densidade $Z$ pode ser recuperado a partir de seu valor inicial $Z_0$ e do processo $D$ da seguinte forma:
$$ Z_k = Z_0 \prod_{j=1}^k D_j \quad \text{para } k = 1, \dots, T $$
e $Z_0 = E_P[D|\mathcal{F}_0]$ [^16.1]. A densidade total $D$ pode então ser escrita como $D = Z_T = Z_0 \prod_{j=1}^T D_j$.

#### Construção de Medidas Martingale Equivalentes via Dk

A parametrização da mudança de medida através do par $(Z_0, D)$ é extremamente útil na construção de EMMs para um dado processo de preços de ativos descontados $S = (S_k)_{k=0,...,T}$. O problema inverso consiste em encontrar um par $(Z_0, D)$ tal que:
1.  $Z_0$ é $\mathcal{F}_0$-mensurável, $Z_0 > 0$ $P$-q.s. e $E_P[Z_0] = 1$.
2.  $D = (D_k)_{k=1,...,T}$ é um processo adaptado, estritamente positivo ($D_k > 0$ $P$-q.s.).
3.  $E_P[D_k | \mathcal{F}_{k-1}] = 1$ para todo $k=1,...,T$.

Se estas condições são satisfeitas, então a variável aleatória $D := Z_0 \prod_{j=1}^T D_j$ define uma medida de probabilidade $Q$ via $dQ = D dP$, que é equivalente a $P$ ($Q \approx P$) [^16.2].

Para que esta medida $Q$ seja uma EMM para $S$, o processo $S$ deve ser um $Q$-martingale, ou seja, $E_Q[S_k | \mathcal{F}_{k-1}] = S_{k-1}$ para $k=1,...,T$. Usando a fórmula de Bayes (3.3) com $U_k = S_k$, a condição de $Q$-martingale torna-se:
$$ E_P[D_k S_k | \mathcal{F}_{k-1}] = S_{k-1} $$
Como $S_{k-1}$ é $\mathcal{F}_{k-1}$-mensurável e $E_P[D_k | \mathcal{F}_{k-1}] = 1$, podemos reescrever a condição como $E_P[D_k S_k | \mathcal{F}_{k-1}] = S_{k-1} E_P[D_k | \mathcal{F}_{k-1}] = E_P[D_k S_{k-1} | \mathcal{F}_{k-1}]$. Portanto, a condição de martingale é equivalente a:
$$ E_P[D_k (S_k - S_{k-1}) | \mathcal{F}_{k-1}] = 0 \quad \text{para todo } k = 1, \dots, T $$
[^16.5]. Adicionalmente, precisamos garantir que $S$ seja $Q$-integrável, i.e., $E_Q[|S_k|] < \infty$ para todo $k$, o que equivale a $E_P[Z_k |S_k|] < \infty$ [^16.5].

A escolha mais simples para $Z_0$ é a constante $Z_0 = 1$. Isso corresponde a requerer que $Q$ e $P$ coincidam em $\mathcal{F}_0$ [^16.6]. Se $\mathcal{F}_0$ for a $\sigma$-álgebra trivial (como frequentemente assumido, por exemplo, quando $S_0$ é determinístico), então $Z_0$ deve ser uma constante $P$-q.s., e a condição $E_P[Z_0]=1$ força $Z_0=1$ a ser a única escolha possível [^16.6]. Neste caso comum, a tarefa de encontrar uma EMM $Q$ reduz-se a encontrar um processo $D=(D_k)_{k=1,...,T}$ adaptado, estritamente positivo, tal que $E_P[D_k|\mathcal{F}_{k-1}]=1$ e $E_P[D_k \Delta S_k | \mathcal{F}_{k-1}]=0$ para todo $k$, onde $\Delta S_k = S_k - S_{k-1}$.

### Aplicações e Exemplos

A abordagem via $D_k$ torna-se particularmente explícita em modelos com estruturas específicas.

#### Caso de Retornos i.i.d.

Consideremos um modelo onde o preço do ativo arriscado descontado $S^1 = \tilde{S}^1 / \tilde{S}^0$ evolui segundo $S^1_k = S^1_0 \prod_{j=1}^k Y_j$, e o ativo sem risco $S^0$ é dado por $S^0_k = (1+r)^k$ [^17.1]. Assumimos que os retornos brutos $Y_1, \dots, Y_T$ são $>0$ e i.i.d. (independentes e identicamente distribuídos) sob $P$. A filtração $\mathbb{F}$ é gerada pelos retornos $Y$ (ou equivalentemente por $S^1$, assumindo $S^0_0=S^1_0=1$), de modo que $\mathcal{F}_0$ é $P$-trivial e $Y_k$ é independente de $\mathcal{F}_{k-1}$ sob $P$ [^17.1]. O processo de preços descontados é $S_k = S^1_k / S^0_k = \prod_{j=1}^k (Y_j / (1+r))$.

A condição de $Q$-martingale para $S$ é $E_Q[S_k | \mathcal{F}_{k-1}] = S_{k-1}$, que na forma multiplicativa é $E_Q[S_k / S_{k-1} | \mathcal{F}_{k-1}] = 1$. Usando $S_k/S_{k-1} = Y_k / (1+r)$ e a fórmula de Bayes (3.3) [^16.3], obtemos:
$$ 1 = E_Q\left[ \frac{Y_k}{1+r} \bigg| \mathcal{F}_{k-1} \right] = E_P\left[ D_k \frac{Y_k}{1+r} \bigg| \mathcal{F}_{k-1} \right] $$
[^17.2]. Para simplificar, procuramos $D_k$ que dependa apenas de $Y_k$, ou seja, $D_k = g_k(Y_k)$ para alguma função mensurável $g_k$, e que seja independente de $\mathcal{F}_{k-1}$ [^17.3]. Como $Y_k$ é independente de $\mathcal{F}_{k-1}$ sob $P$, esta escolha é consistente. As condições para $(Z_0=1, D)$ definirem uma EMM tornam-se:
1.  $g_k(Y_k) > 0$ $P$-q.s.
2.  $E_P[D_k | \mathcal{F}_{k-1}] = E_P[g_k(Y_k) | \mathcal{F}_{k-1}] = E_P[g_k(Y_k)] = 1$ (devido à independência) [^17.4].
3.  $E_P[D_k Y_k / (1+r) | \mathcal{F}_{k-1}] = E_P[g_k(Y_k) Y_k / (1+r) | \mathcal{F}_{k-1}] = \frac{1}{1+r} E_P[Y_k g_k(Y_k)] = 1$ (devido à independência) [^17.5].

Como os $Y_k$ são i.i.d. sob $P$, suas distribuições são as mesmas. Portanto, se encontrarmos uma função $g_1 > 0$ tal que $E_P[g_1(Y_1)] = 1$ e $E_P[Y_1 g_1(Y_1)] = 1+r$, podemos escolher $g_k = g_1$ para todo $k$ [^17.6]. Neste caso, a densidade da EMM $Q$ é $D = \prod_{j=1}^T g_1(Y_j)$. Sob esta medida $Q$, pode-se mostrar que os retornos $Y_1, \dots, Y_T$ permanecem i.i.d. [^17.7]. A integrabilidade $E_Q[|S_k|] < \infty$ é automaticamente satisfeita porque $S_k > 0$ e $E_Q[S_k] = S_0 = 1$ pela propriedade de martingale [^17.1].

#### Exemplo: Modelo Multinomial

No modelo multinomial com retornos $Y_k$ tomando valores discretos $1+y_j$ com probabilidades $P[Y_k = 1+y_j] = p_j > 0$ para $j \in \mathbb{N}$ (ou um conjunto finito $\\{1, ..., m\\}$) [^18.1], a abordagem acima se traduz em encontrar probabilidades $q_j > 0$ para $j$ tais que $p_j > 0$, que satisfaçam:
$$ \sum_{j: p_j>0} q_j = 1 \quad \text{e} \quad \sum_{j: p_j>0} q_j (1+y_j) = 1+r $$
A segunda equação é equivalente a $\sum_{j: p_j>0} q_j y_j = r$ [^18.3]. Aqui, $q_j$ corresponde a $Q[Y_k = 1+y_j]$ e está relacionado a $g_1$ por $q_j = p_j g_1(1+y_j)$ [^18.1]. Se o número de resultados possíveis $m$ for maior que 2 e os $y_j$ forem distintos, geralmente existe um número infinito de soluções para $(q_j)$, desde que $r$ esteja estritamente entre o menor e o maior retorno possível, $y_{min} < r < y_{max}$ (ver Corolário 1.4 [^7.1] e Corolário 2.2 [^13.1]) [^18.3].

#### Exemplo: Retornos Lognormais

Se os retornos sob $P$ são lognormais i.i.d., $Y_k = e^{\sigma U_k + b}$, onde $U_k \sim N(0,1)$ i.i.d. [^18.2]. Tentamos encontrar a função $g_1$ na forma $D_k = g_1(Y_k)$. É equivalente e talvez mais conveniente procurar $D_k$ como uma função de $U_k$, $D_k = \tilde{g}_1(U_k)$. Uma escolha comum é a forma exponencial: $D_k = e^{\alpha U_k + \beta}$ [^18.4]. As condições $E_P[D_k]=1$ e $E_P[D_k Y_k]=1+r$ tornam-se:
1.  $E_P[e^{\alpha U_k + \beta}] = e^{\beta} E_P[e^{\alpha U_k}] = e^{\beta} e^{\alpha^2/2} = 1$ [^18.4]. Daqui, $\beta = -\alpha^2/2$.
2.  $E_P[D_k Y_k] = E_P[e^{\alpha U_k + \beta} e^{\sigma U_k + b}] = E_P[e^{(\alpha+\sigma)U_k + b + \beta}] = e^{b+\beta} E_P[e^{(\alpha+\sigma)U_k}] = e^{b+\beta} e^{(\alpha+\sigma)^2/2} = 1+r$ [^19.1].

Substituindo $\beta = -\alpha^2/2$, a segunda equação torna-se $e^{b - \alpha^2/2 + (\alpha^2 + 2\alpha\sigma + \sigma^2)/2} = e^{b + \alpha\sigma + \sigma^2/2} = 1+r$. Tomando o logaritmo, obtemos $b + \alpha\sigma + \sigma^2/2 = \log(1+r)$. Resolvendo para $\alpha$:
$$ \alpha = \frac{\log(1+r) - b - \sigma^2/2}{\sigma} $$
[^19.1]. Definindo $\gamma = -\alpha$, temos:
$$ \gamma = \frac{b + \sigma^2/2 - \log(1+r)}{\sigma} $$
e $\beta = -\alpha^2/2 = -\gamma^2/2$. Assim, $D_k = e^{-\gamma U_k - \gamma^2/2}$ [^19.1]. Esta construção fornece uma EMM $Q$ para o modelo de retornos lognormais.

### Conclusão

O processo $D = (D_k)_{k=1,...,T}$, definido como as razões $Z_k/Z_{k-1}$ do processo de densidade $P$-martingale $Z$, captura a essência da mudança de medida de $P$ para $Q$ em uma base passo a passo. A propriedade fundamental $E_P[D_k | \mathcal{F}_{k-1}] = 1$ e a fórmula de Bayes $E_Q[U_k | \mathcal{F}_{k-1}] = E_P[D_k U_k | \mathcal{F}_{k-1}]$ [^16.3] solidificam a interpretação de $D_k$ como a **densidade condicional de um passo**. Esta perspectiva não só elucida a relação dinâmica entre as medidas $P$ e $Q$, mas também fornece uma ferramenta construtiva poderosa para encontrar medidas martingale equivalentes $Q$. A condição de $Q$-martingale para um processo $S$, $E_P[D_k (S_k - S_{k-1}) | \mathcal{F}_{k-1}] = 0$ [^16.5], juntamente com as propriedades de $D_k$, forma a base para a construção de EMMs em modelos específicos, como os de retornos i.i.d., multinomial e lognormal, conectando diretamente a teoria abstrata de EMMs com aplicações práticas em precificação e hedging.

### Referências

[^7.1]: Corolário 1.4, Página 38.
[^8.1]: Teorema 2.1 (Dalang/Morton/Willinger), Página 39.
[^9.1]: Teorema 2.1 e Comentários, Páginas 39-40.
[^13.1]: Corolário 2.2, Página 44.
[^14.1]: Introdução da Seção 2.3, Página 45.
[^14.2]: Definição de $Q \approx P$ e densidade $D$, Equação (3.1), Página 45.
[^14.3]: Definição do processo de densidade $Z_k$, Página 45.
[^14.4]: Propriedade $Z_k > 0$ P-q.s., Página 45.
[^15.1]: Definição de $D_k = Z_k/Z_{k-1}$, Página 46.
[^15.2]: $Z$ é estritamente positivo, Página 45-46.
[^15.3]: $D$ é adaptado e estritamente positivo, Página 46.
[^15.4]: Propriedade $E_P[D_k | \mathcal{F}_{k-1}] = 1$, Página 46.
[^15.5]: Lemma 3.1 (propriedades de $Z_k$ e fórmula de Bayes (3.2)), Página 46.
[^16.1]: Recuperação de $Z_k$ a partir de $Z_0$ e $D_j$, Página 47.
[^16.2]: Construção de $Q \approx P$ a partir de $(Z_0, D)$, Página 47.
[^16.3]: Fórmula de Bayes (3.3), Página 47.
[^16.4]: Interpretação de $D_k$ como "one-step conditional densities", Página 47.
[^16.5]: Condição de Q-martingale em termos de $D_k$ e integrabilidade, Página 47.
[^16.6]: Escolha $Z_0=1$, Página 47.
[^17.1]: Cenário de retornos i.i.d. e setup do modelo, Página 48.
[^17.2]: Condição de Q-martingale para retornos i.i.d. via (3.3), Página 48.
[^17.3]: Tentativa de $D_k = g_k(Y_k)$ independente de $\mathcal{F}_{k-1}$, Página 48.
[^17.4]: Condição $E_P[g_k(Y_k)] = 1$, Página 48.
[^17.5]: Condição $E_P[Y_k g_k(Y_k)] = 1+r$, Página 48.
[^17.6]: Escolha $g_k = g_1$ devido a i.i.d., Página 48.
[^17.7]: Definição da EMM e propriedade i.i.d. sob Q, Página 48-49.
[^18.1]: Aplicação ao caso discreto/multinomial, Página 49.
[^18.2]: Setup do caso lognormal, Página 49.
[^18.3]: Condições para o modelo multinomial ($q_j$), Página 49.
[^18.4]: Tentativa de $D_k = e^{\alpha U_k + \beta}$ no caso lognormal e condição $E_P[D_k]=1$, Página 49.
[^19.1]: Derivação de $\alpha$ e $\gamma$ para o caso lognormal usando $E_P[D_k Y_k]=1+r$, Páginas 50.

<!-- END -->