## Capítulo 2.3: Medidas de Probabilidade Equivalentes e o Processo Densidade

### Introdução

Como vimos na discussão do Teorema Fundamental da Precificação de Ativos (FTAP) em sua forma mais simples (Teorema 2.1 [^18]), as **medidas martingales equivalentes (EMM)** desempenham um papel crucial na finança matemática [^30]. Sua existência está ligada à ausência de arbitragem [^18], e sua utilização se torna ainda mais pronunciada em problemas de precificação e hedging de opções, como veremos posteriormente. Nesta seção, iniciaremos o estudo das relações entre cálculos e propriedades probabilísticas sob duas medidas de probabilidade $Q$ e $P$ quando estas são equivalentes ($Q \approx P$) [^30]. Investigaremos como construir uma EMM para um processo $S$ em certas situações e, fundamentalmente, como relacionar expectativas e propriedades martingales entre essas duas medidas [^30].

Começamos com um espaço de probabilidade filtrado $(\Omega, \mathcal{F}, \mathbb{F} = (\mathcal{F}_k)_{k=0,1,...,T}, P)$ em tempo discreto finito. Assumimos a existência de outra medida de probabilidade $Q$ sobre $\mathcal{F}$ tal que $Q$ é **equivalente** a $P$ [^30].

> Lembremos que duas medidas de probabilidade $Q$ e $P$ sobre $\mathcal{F}$ são ditas **equivalentes** (em $\mathcal{F}$), denotado por $Q \approx P$ (em $\mathcal{F}$), se elas possuem os mesmos conjuntos nulos (em $\mathcal{F}$). Isto é, para cada conjunto $A \in \mathcal{F}$, temos $P[A] = 0$ se e somente se $Q[A] = 0$ [^3]. Intuitivamente, isso significa que, embora $P$ e $Q$ possam diferir em suas avaliações quantitativas, elas concordam qualitativamente sobre o que é "possível" ou "impossível" [^3].

Esta equivalência é a base para a mudança de medida, uma técnica poderosa em finanças quantitativas.

### Conceitos Fundamentais

**A Derivada de Radon-Nikodým e a Relação Fundamental**

Dado que $Q \approx P$ em $\mathcal{F}$, o teorema de Radon-Nikodým garante a existência de uma **derivada de Radon-Nikodým** (ou densidade) de $Q$ com respeito a $P$, denotada por $D = \frac{dQ}{dP}$ [^31]. Esta $D$ é uma variável aleatória estritamente positiva $P$-quase certamente ($D > 0$ $P$-q.s.), devido à equivalência $Q \approx P$ [^31]. A propriedade fundamental que conecta as expectativas sob $Q$ e $P$ é dada por:

> $$ E_Q[Y] = E_P[YD] \quad (3.1) $$
> para toda variável aleatória $Y \ge 0$ [^31].

Em particular, tomando $Y=1$, temos $E_P[D] = E_Q[1] = 1$ [^31]. A equação (3.1) pode ser escrita na forma integral como $\int_\Omega Y dQ = \int_\Omega Y D dP$, o que ajuda a explicar a notação [^31]. O ponto central desta fórmula é que ela nos permite calcular expectativas sob $Q$ usando expectativas sob $P$, e vice-versa [^31]. Às vezes, escreve-se $D = \frac{dQ}{dP}|_{\mathcal{F}}$ para enfatizar que $D$ é a densidade em toda a $\sigma$-álgebra $\mathcal{F}$ [^31].

**O Processo Densidade**

Para obter regras de transformação similares para esperanças condicionais, introduzimos o **processo densidade** $Z = (Z_k)_{k=0,1,...,T}$ (às vezes denotado por $Z^Q$ ou $Z^{Q;P}$) definido por [^32]:

> $$ Z_k := E_P[D | \mathcal{F}_k] = E_P\left[\frac{dQ}{dP} \middle| \mathcal{F}_k\right] \quad \text{para } k = 0, 1, ..., T $$

Como $D > 0$ $P$-q.s. e a esperança condicional preserva positividade, o processo $Z$ é estritamente positivo no sentido de que $Z_k > 0$ $P$-q.s. para cada $k$, ou também $P[Z_k > 0 \text{ para todo } k] = 1$ [^32]. Pela propriedade da torre da esperança condicional, $Z$ é um **P-martingale** em relação à filtração $\mathbb{F}$. O processo $Z$ é chamado de processo densidade (de $Q$, com respeito a $P$) [^32], e o próximo lema esclarece o porquê.

**Lema 3.1: Propriedades Fundamentais da Mudança de Medida** [^33]

1.  Para todo $k \in \\{0, 1, ..., T\\}$ e qualquer $A \in \mathcal{F}_k$ ou qualquer variável aleatória $Y$ $\mathcal{F}_k$-mensurável tal que $Y \ge 0$ ou $Y \in L^1(Q)$, temos:
    > $$ Q[A] = E_P[Z_k I_A] \quad \text{e} \quad E_Q[Y] = E_P[Z_k Y] $$
    Isso significa que $Z_k$ é a densidade de $Q$ com respeito a $P$ na $\sigma$-álgebra $\mathcal{F}_k$, e também escrevemos $Z_k = \frac{dQ}{dP}|_{\mathcal{F}_k}$ [^33].

2.  Se $j \le k$ e $U_k$ é $\mathcal{F}_k$-mensurável e $U_k \ge 0$ ou $U_k \in L^1(Q)$, então temos a **Fórmula de Bayes** para esperanças condicionais:
    > $$ E_Q[U_k | \mathcal{F}_j] = \frac{1}{Z_j} E_P[Z_k U_k | \mathcal{F}_j] \quad Q\text{-q.s.} \quad (3.2) $$
    Esta fórmula crucial nos diz como as esperanças condicionais sob $Q$ e $P$ estão relacionadas [^34].

3.  Um processo $N = (N_k)_{k=0,1,...,T}$ adaptado a $\mathbb{F}$ é um **Q-martingale** se e somente se o processo produto $ZN = (Z_k N_k)_{k=0,1,...,T}$ é um **P-martingale** [^35]. Isso estabelece a ligação fundamental entre as propriedades martingales sob $P$ e $Q$ [^35].

A prova do Lema 3.1 é um exercício padrão da teoria da probabilidade no uso de esperanças condicionais e não será detalhada aqui, mas é fortemente recomendada [^33]. Note que se $\mathcal{F}_T$ for estritamente menor que $\mathcal{F}$ (o que não é o caso usual em tempo finito, onde $\mathcal{F}=\mathcal{F}_T$), teremos $Z_T \neq D$ em geral [^33].

**Densidades Condicionais de Um Passo**

Como o processo densidade $Z$ é estritamente positivo [^32], podemos definir o processo $D = (D_k)_{k=1,...,T}$ por [^36]:
$$ D_k := \frac{Z_k}{Z_{k-1}} \quad \text{para } k = 1, ..., T $$
O processo $D$ é adaptado, estritamente positivo e satisfaz, por definição e pelo fato de $Z$ ser um P-martingale:
$$ E_P[D_k | \mathcal{F}_{k-1}] = E_P\left[\frac{Z_k}{Z_{k-1}} \middle| \mathcal{F}_{k-1}\right] = \frac{1}{Z_{k-1}} E_P[Z_k | \mathcal{F}_{k-1}] = \frac{Z_{k-1}}{Z_{k-1}} = 1 $$
[^36]. Podemos, claro, recuperar $Z$ a partir de $Z_0$ e $D$ via [^37]:
$$ Z_k = Z_0 \prod_{j=1}^k D_j \quad \text{para } k = 0, 1, ..., T $$
(onde o produto vazio para $k=0$ é 1).

Inversamente, se começarmos com um par $(Z_0, D)$ onde $Z_0$ é $\mathcal{F}_0$-mensurável, $Z_0 > 0$ $P$-q.s. com $E_P[Z_0] = 1$, e $D = (D_k)_{k=1,...,T}$ é um processo adaptado estritamente positivo com $E_P[D_k | \mathcal{F}_{k-1}] = 1$ para todo $k$, podemos definir uma medida de probabilidade $Q \approx P$ via [^37]:
$$ \frac{dQ}{dP} := Z_T = Z_0 \prod_{j=1}^T D_j $$
Escrita em termos de $D$, a fórmula de Bayes (3.2) para $j = k-1$ torna-se [^38]:
> $$ E_Q[U_k | \mathcal{F}_{k-1}] = E_P[D_k U_k | \mathcal{F}_{k-1}] \quad (3.3) $$
Isso mostra que as razões $D_k$ desempenham o papel de "densidades condicionais de um passo" de $Q$ com respeito a $P$ [^38].

**Construção de Medidas Martingales Equivalentes**

A parametrização via $(Z_0, D)$ é muito útil quando queremos construir uma medida martingale equivalente para um dado processo $S$ [^39]. Precisamos encontrar:
1.  Uma variável aleatória $Z_0$ que seja $\mathcal{F}_0$-mensurável, $Z_0 > 0$ $P$-q.s., e $E_P[Z_0] = 1$.
2.  Um processo $D = (D_k)_{k=1,...,T}$ adaptado, estritamente positivo, tal que $E_P[D_k | \mathcal{F}_{k-1}] = 1$ para todo $k$.
Estas são as propriedades necessárias para obter uma medida de probabilidade $Q$ equivalente a $P$ [^37]. Adicionalmente, para que $S$ seja um $Q$-martingale, precisamos (usando (3.3) com $U_k = S_k$) que $E_Q[S_k | \mathcal{F}_{k-1}] = S_{k-1}$, o que se traduz em:
3.  $E_P[D_k S_k | \mathcal{F}_{k-1}] = S_{k-1}$, ou equivalentemente, $E_P[D_k (S_k - S_{k-1}) | \mathcal{F}_{k-1}] = 0$ para todo $k$ [^39].

(Para sermos precisos, também precisamos garantir que $S$ seja $Q$-integrável, ou seja, $E_Q[|S_k|] < \infty$ para todo $k$. Isso equivale à condição de integrabilidade $E_P[Z_k |S_k|] < \infty$ para todo $k$ [^39]).

A escolha mais simples para $Z_0$ é a constante $Z_0 = 1$ [^40]. Isso equivale a dizer que $Q$ e $P$ devem coincidir em $\mathcal{F}_0$. Se $\mathcal{F}_0$ for $P$-trivial (i.e., $P[A] \in \\{0, 1\\}$ para todo $A \in \mathcal{F}_0$), como é frequentemente o caso, então toda variável aleatória $\mathcal{F}_0$-mensurável é $P$-q.s. constante, e então $Z_0 = 1$ é na verdade a única escolha possível (pois devemos ter $E_P[Z_0] = 1$) [^40]. O desafio então reside em encontrar o processo $D = (D_k)$ que satisfaça as condições 2 e 3.

### Conclusão

Nesta seção, estabelecemos as ferramentas fundamentais para trabalhar com medidas de probabilidade equivalentes $P$ e $Q$. A **derivada de Radon-Nikodým** $D = dQ/dP$ e o **processo densidade** $Z_k = E_P[D|\mathcal{F}_k]$ são centrais, permitindo a conversão de expectativas (Eq. 3.1) e esperanças condicionais (Fórmula de Bayes, Eq. 3.2) entre as duas medidas. Vimos também como a propriedade martingale se transforma (Lema 3.1(3)). A introdução das **densidades condicionais de um passo** $D_k = Z_k/Z_{k-1}$ fornece uma visão dinâmica da relação entre $P$ e $Q$ (Eq. 3.3) e oferece um caminho para a construção explícita de uma medida $Q \approx P$ sob a qual um processo $S$ se torna um martingale, conectando diretamente com a busca por medidas martingales equivalentes, cuja existência é garantida pelo FTAP (Teorema 2.1 [^18]) em mercados sem arbitragem. Estas ferramentas são indispensáveis para a teoria de precificação neutra ao risco.

### Referências
[^1]: Remarks. 1) An arbitrage opportunity...
[^2]: 2) One can also introduce the condition (NA+)...
[^3]: Recall that two probability measures Q and P on F are equivalent (on F), written as Q ≈ P (on F), if they have the same nullsets (in F), i.e. if for each set A (in F), we have P[A] = 0 if and only if Q[A] = 0. Intuitively, this means that while P and Q may differ in their quantitative assessments, they qualitatively agree on what is "possible or impossible".
[^4]: Example. If we construct the multinomial model...
[^5]: Lemma 1.2. If there exists a probability measure Q ≈ P on Fr such that S is a Q-martingale, then S is arbitrage-free.
[^6]: Proof. If S is a Q-martingale... EQ[VT(φ)] = EQ[Vo(φ)] = 0.
[^7]: Now suppose in addition that Q ≈ P on Fr, so that Q-a.s. and P-a.s. are the same thing for all events in Fr. If φ = (0, ϑ) is an admissible self-financing strategy with VT(φ) ≥ 0 P-a.s., then also VT(φ) ≥ 0 Q-a.s. But EQ[VT(φ)] = 0 by the above argument, and so we must have VT(φ) = 0 Q-a.s., hence also VT(φ) = 0 P-a.s. By Proposition 1.1, S is therefore arbitrage-free.
[^8]: Remark 1.3. 1) It would be enough if S is only a local Q-martingale...
[^9]: 2) An alternative proof of Lemma 1.2 goes as follows...
[^10]: 3) We can also give a complete proof of Lemma 1.2 which relies only on proved results...
[^11]: Example. Consider the multinomial model... To find Q ≈ P such that S¹ = S̃¹/S⁰ is a Q-martingale... we need to find one-step transition probabilities in the open interval (0, 1) such that EQ[S̃k¹/S̃k⁰ | Fk−1] = S̃k−1¹/S̃k−1⁰ for all k.
[^12]: Because S̃k¹/S̃k⁰ / S̃k−1¹/S̃k−1⁰ = Yk / (1+r), we equivalently need EQ[Yk/(1+r) | Fk−1] = 1 for all k.
[^13]: Now fix k and look at a node corresponding to an atom A(k−1)... on the atom A(k−1), EQ[Yk | Fk−1] = EQ[Yk | A(k−1)] = Σ qj(A(k−1))(1 + yj) = 1 + Σ qj(A(k−1))yj.
[^14]: and we want this to equal 1+r... The above conditional expectation equals 1 + r if and only if the equation Σ qj(A(k−1))yj = r has a solution... Because we want all the qj(A(k−1)) to lie in (0,1)... this can clearly be achieved if and only if ym > r > y1...
[^15]: But we also see that there are clearly many Q\' ≈ P on Fr such that S̃¹/S̃⁰ is a Q\'-martingale...
[^16]: Corollary 1.4. In the multinomial model with parameters y1 < ··· < ym and r, there exists a probability measure Q ≈ P such that S̃¹/S̃⁰ is a Q-martingale if and only if y1 < r < ym.
[^17]: Corollary 1.5. In the binomial model with parameters u > d and r, there exists a probability measure Q ≈ P such that S̃¹/S̃⁰ is a Q-martingale if and only if u > r > d... Q is unique (on FT)... Q[Yk = 1 + u] = q* = (r-d)/(u-d)...
[^18]: Theorem 2.1 (Dalang/Morton/Willinger). Consider a (discounted) financial market model in finite discrete time. Then S is arbitrage-free if and only if there exists an equivalent martingale measure for S. In brief: (NA) ⇔ IPe(S) ≠ ∅ ⇔ IPe,loc(S) ≠ ∅.
[^19]: 1) The crucial significance of Theorem 2.1 is that it translates the economic/financial condition of absence of arbitrage into an equivalent, purely mathematical/probabilistic condition...
[^20]: 2) The classical theorems in martingale theory on gambling say that one cannot win...
[^21]: 3) Note that we make no integrability assumptions about S (under P); so it is also noteworthy that S, being a Q-martingale, is automatically integrable under (some) Q.
[^22]: Proving Theorem 2.1 is not elementary if one wants to allow models where the underlying probability space (Ω, F, P) is infinite...
[^23]: Due to Lemma 1.2 (plus Remark 1.3) and IPe ⊆ IPe,loc, we only need to prove that absence of arbitrage implies the existence of an equivalent martingale measure for S. By Proposition 1.1, (NA) is equivalent to G\' ∩ L⁰+(FT) = {0}, where G\' = {GT(ϑ) : ϑ is Rd-valued and predictable} is the space of all final positions one can generate from initial wealth 0 by self-financing...
[^24]: Graphical illustration of the condition G\' ∩ L⁰+(FT) = {0}
[^25]: As a consequence, the two sets L⁰+(FT) and G\' can be separated by a hyperplane...
[^26]: As one can see from the above scheme of proof, the existence of an EMM follows from the existence of a separating hyperplane... Because the set IPe(S) is obviously convex...
[^27]: Proof of Theorem 2.1 for Ω (or FT) finite. If Ω (or FT) is finite... we can identify L⁰(FT) with the finite-dimensional space Rn and L⁰+(FT) with Rn+. ... The set G\' ⊆ L⁰(FT), which is obviously linear, can then be identified with a linear subspace H of Rn, and so (NA) translates into H ∩ Rn+ = {0} due to Proposition 1.1.
[^28]: Recall that a set A ∈ FT is an atom in FT if P[A] > 0...
[^29]: We consider the set of all FT-measurable Z ≥ 0 with Σ Z_A = 1 and identify this with the subset K = {z ∈ Rn+ : Σ zi = 1}... Then K ⊂ Rn+ and K does not contain the vector 0, so that we must have H ∩ K = ∅. Moreover, K is convex and compact, and so a classical separation theorem... implies that there exists a vector λ ∈ Rn with λ ≠ 0 such that (2.1) λT h = 0 for all h ∈ H and (2.2) λT z > 0 for all z ∈ K.
[^30]: 2.3 Equivalent (martingale) measures... In this section, we therefore start to study how one can relate computations and probabilistic properties under Q and under P to each other if Q ≈ P, and we also have a look at how one might actually construct an EMM for a given process S in certain situations. We begin with (Ω, F) and a filtration IF = (Fk)k=0,1,...,T in finite discrete time. On F, we have two probability measures Q and P, and we assume that Q ≈ P.
[^31]: Then the Radon-Nikodým theorem tells us that there exists a density dQ/dP =: D; this is a random variable D > 0 P-a.s. (because Q ≈ P) such that Q[A] = EP[DIA] for all A ∈ F, or more generally (3.1) EQ[Y] = EP[YD] for all random variables Y ≥ 0. In particular, EP[D] = EQ[1] = 1. One sometimes writes (3.1) in integral form as ∫Ω Y dQ = ∫Ω Y D dP which explains the notation to some extent. The point of these formulae is that they tell us how to compute Q-expectations in terms of P-expectations and vice versa. Sometimes one also writes D = dQ/dP|F to emphasise that we have Q[A] = EP[DIA] for all A ∈ F, and one sometimes explicitly calls D the density of Q with respect to P on F.
[^32]: To get similar transformation rules for conditional expectations, we introduce the P-martingale Z (sometimes denoted more explicitly by ZQ or ZQ;P) by Zk := EP[D|Fk] = EP[dQ/dP|Fk] for k = 0, 1, ..., T. Because D > 0 P-a.s., the process Z = (Zk)k=0,1,...,T is strictly positive in the sense that Zk > 0 P-a.s. for each k, or also P[Zk > 0 for all k] = 1. Z is called the density process (of Q, with respect to P); the next result makes it clear why.
[^33]: Lemma 3.1. 1) For every k ∈ {0,1,...,T} and any A ∈ Fk or any Fk-measurable random variable Y ≥ 0 or Y ∈ L¹(Q), we have Q[A] = EP[ZKIA] and EQ[Y] = EP[ZkY], respectively. This means that Zk is the density of Q with respect to P on Fk, and we also write sometimes Zk = dQ/dP|Fk. ... The proof of Lemma 3.1 is a standard exercise from probability theory in the use of conditional expectations. We do not give it here, but strongly recommend to do this as an [→ exercise]. Note that if FT is smaller than F, we have ZT ≠ D in general.
[^34]: 2) If j ≤ k and Uk is Fk-measurable and either ≥ 0 or in L¹(Q), then we have the Bayes formula (3.2) EQ[Uk|Fj] = (1/Zj) EP[ZkUk | Fj] Q-a.s. This tells us how conditional expectations under Q and P are related to each other.
[^35]: 3) A process N = (Nk)k=0,1,...,T which is adapted to IF is a Q-martingale if and only if the product ZN is a P-martingale. This tells us how martingale properties under P and Q are related to each other.
[^36]: Because Z is strictly positive, we can define Dk := Zk/Zk-1 for k = 1, ..., T. The process D = (Dk)k=1,...,T is adapted, strictly positive and satisfies by its definition EP[Dk|Fk-1] = 1, because Z is a P-martingale.
[^37]: and we can of course recover Z from Z0 and D via Zk = Z0 Π(j=1 to k) Dj for k = 0,1,...,T. So every Q ≈ P induces via Z a pair (Z0, D). If we conversely start with a pair (Z0, D) with the above properties (i.e. Z0 is F0-measurable, Z0 > 0 P-a.s. with EP[Z0] = 1, and D is adapted and strictly positive with EP[Dk|Fk−1] = 1 for all k), we can define a probability measure Q ≈ P via dQ/dP := ZT = Z0 Π(j=1 to T) Dj.
[^38]: Written in terms of D, the Bayes formula (3.2) for j = k − 1 becomes (3.3) EQ[Uk|Fk-1] = EP[DkUk|Fk-1]. This shows that the ratios Dk play the role of “one-step conditional densities" of Q with respect to P.
[^39]: The above parametrisation is very simple and yet very useful when we want to construct an equivalent martingale measure for a given process S. All we need to find are an F0-measurable random variable Z0 > 0 P-a.s. with EP[Z0] = 1 and an adapted strictly positive process D = (Dk)k=1,...,T satisfying EP[Dk|Fk−1] = 1 for all k (these are the properties required to get an equivalent probability measure Q), and in addition EP[Dk(Sk - Sk−1) | Fk−1] = 0 for all k. Indeed, the latter condition is, in view of (3.3), simply the martingale property of S under the measure Q determined by (Z0, D). (To be accurate, we also need to make sure that S is Q-integrable, meaning that EQ[|Sk|] < ∞ for all k; this amounts to the integrability requirement that EP[Zk|Sk|] < ∞ for all k, where Zk = Z0 Π(j=1 to k) Dj.)
[^40]: The simplest choice for Z0 is clearly the constant Z0 = 1; this amounts to saying that Q and P should coincide on F0. If F0 is P-trivial (i.e. P[A] ∈ {0,1} for all A ∈ F0) as is often the case, then every F0-measurable random variable is P-a.s. constant, and then Z0 = 1 is actually the only possible choice (because we must have EP[Z0] = 1).

<!-- END -->