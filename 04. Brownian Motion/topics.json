{
  "topics": [
    {
      "topic": "Basics about Brownian Motion",
      "sub_topics": [
        "Brownian motion (BM) is the continuous-time analogue of the Cox-Ross-Rubinstein binomial model and converges to the Black-Scholes model. It serves as the stochastic process driving the Black-Scholes model and is conceptually a dynamic version of the normal distribution, playing a central role in modeling stochastic phenomena and holding fundamental importance in various areas, including quantitative finance. The notation W is used in honor of Norbert Wiener, who provided the first rigorous proof of its existence, although Louis Bachelier and Albert Einstein had previously introduced and utilized it in finance and physics, respectively.",
        "A Brownian motion W with respect to a probability measure P and a filtration IF = (Ft)t\u22650 is a real-valued stochastic process W = (Wt)t\u22650 adapted to IF, starting at 0 (Wo = 0 P-a.s.), and satisfying specific properties. Two equivalent definitions exist: (1) For s < t, the increment Wt \u2013 Ws is independent (under P) of Fs with (under P) a normal distribution N(0, t \u2013 s), and W has continuous trajectories, meaning that for P-almost all \u03c9 \u2208 \u03a9, the function t \u2192 Wt(\u03c9) on [0, \u221e) is continuous. (2) Without filtration IF, W starts at 0, has continuous trajectories, and for any n \u2208 \u2115 and times 0 = t0 < t1 < ... < tn < \u221e, the increments Wti - Wti-1 are independent with Wti - Wti-1 ~ N(0, ti - ti-1), or N(0, (ti - ti-1)Im\u00d7m) if W is \u211dm-valued, reflecting independent stationary increments with a specific normal distribution. The two definitions are equivalent if IF is the filtration IFW generated by W (and made right-continuous and P-complete).",
        "Brownian motion in \u211dm is an adapted \u211dm-valued stochastic process null at 0 such that the condition for increments holds with N(0, t \u2013 s) replaced by N(0, (t \u2013 s)Im\u00d7m), where Im\u00d7m denotes the m \u00d7 m identity matrix, which is equivalent to saying that the m components are all real-valued Brownian motions and independent (as processes).",
        "Several transformations produce a new Brownian motion from a given one: W1 := \u2212W is a BM; W2 := Wt+T \u2212 WT, t \u2265 0, is a BM for any T \u2208 (0, \u221e) (restarting at a fixed time T); W3 := cWt, t \u2265 0, is a BM for any c \u2208 \u211d, c \u2260 0 (rescaling in space and time); W4 := WT\u2212t \u2212 WT, 0 \u2264 t \u2264 T, is a BM on [0, T] for any T \u2208 (0, \u221e) (time-reversal); the process Wt*, t \u2265 0, defined by tW1/t for t > 0 and 0 for t = 0, is a BM (inversion of small and large times). These transformations can be used to prove results about BM.",
        "The asymptotic behavior of BM as t tends to infinity is related to the behavior of BM near time 0, and vice versa. The Law of the Iterated Logarithm (LIL) provides insights into the asymptotic behavior of Brownian motion, with both global and local versions. The global LIL describes how Wt oscillates between \u00b1\u221a(2t log(log t)) as t approaches infinity, while the local LIL describes the oscillations of Wt+h - Wt around the level of Wt as h approaches 0. Specifically, with glob(t) := \u221a(2t log(log t)), the limit superior and inferior of Wt/glob(t) as t approaches infinity are +1 and -1 P-a.s., respectively, and similarly for the local version with loc(h) := \u221a(2h log(log h)). The local law of the iterated logarithm describes the oscillations of the trajectory u \u2192 W1(w) around the level W1(w), indicating that BM crosses the level 0 (or any level a) infinitely often and manages to perform infinite crossings in an arbitrarily short period of time.",
        "Brownian motion trajectories are continuous but nowhere differentiable, exhibiting irregular behavior related to the fact that BM trajectories are continuous functions with a nonzero quadratic variation. The infinitesimal increments dWt have the property (dWt)\u00b2 = dt, which is a purely formal but helpful concept for understanding stochastic calculus and It\u00f4's formula. The quadratic variation of Brownian motion W is defined as (W)t = t, meaning that along a refining sequence of partitions (In)n\u2208N of [0, \u221e) with mesh size approaching 0, the sum of squared increments of W converges to t with probability 1. Heuristically, the quadratic variation can be understood by the relation (dWt)\u00b2 = dt, where dWt represents infinitesimal increments of the BM. A more precise description involves defining the p-variation of a function g on [0, T] along a partition \u03a0. Continuous functions with nonzero quadratic variation must have infinite variation, and the variation of W(w) is +\u221e for almost all trajectories W(w).",
        "The limit, called [M]t, of the sequence (QI(M))n\u2208\u2115 is not t, but some random variable (Ft-measurable), and the convergence does not hold almost certainly in probability for general local martingales M instead of Brownian motion W."
      ]
    },
    {
      "topic": "Martingale Properties and Results",
      "sub_topics": [
        "A martingale M = (Mt) with respect to P and IF is a real-valued stochastic process adapted to IF, P-integrable (each Mt is in L1(P)), and satisfies the martingale property: E[Mt | Fs] = Ms P-a.s. for s < t. If the inequality is '<', it's a supermartingale; if '>', it's a submartingale. A general result from the theory of stochastic processes states that any martingale has a version with nice trajectories (RCLL, i.e., right-continuous with left limits).",
        "A stopping time \u03c4 with respect to IF is a mapping \u03c4 : \u03a9 \u2192 [0, \u221e] such that {\u03c4 \u2264 t} \u2208 Ft for all t \u2265 0, and one of the standard examples is the first time that some adapted right-continuous process X (e.g., Brownian motion W) hits an open set B (e.g., (a, \u221e)), i.e., \u03c4 := inf{t > 0 : Xt \u2208 B}.",
        "One of the most useful properties of martingales is that the martingale property E[Mt | Fs] = Ms and its consequences often extend to the case where the fixed times s < t are replaced by stopping times \u03c3 < \u03c4; to make sense of this, it is necessary to define the \u03c3-algebra of events observable up to time \u03c3 as F\u03c3 := {A \u2208 F : A \u2229 {\u03c3 \u2264 t} \u2208 Ft for all t \u2265 0}.",
        "The value of M at the stopping time \u03c4 is defined as M\u03c4(\u03c9) := M\u03c4(\u03c9)(\u03c9), and if \u03c4 is a stopping time and M is an adapted process with RC trajectories, then M\u03c4 is F\u03c4-measurable; the stopped process M\u03c4 = (Mt\u2227\u03c4)t\u22650 is defined by Mt\u03c4 := Mt\u2227\u03c4 for all t > 0, and if M is adapted with RC trajectories and \u03c4 is a stopping time, then M\u03c4 will also be adapted and have RC trajectories.",
        "The Stopping Theorem asserts that for a (P, IF)-martingale M = (Mt)t\u22650 with RC trajectories and IF-stopping times \u03c3 \u2264 \u03c4, if \u03c4 is bounded by some T \u2208 (0, \u221e) or M is uniformly integrable, then M\u03c3, M\u03c4 are in L1(P) and E[M\u03c4 | F\u03c3] = M\u03c3 P-a.s.",
        "For any RC martingale M and any stopping time \u03c4, we have E[M\u03c4\u2227t|Fs] = M\u03c4\u2227s for s \u2264 t, i.e., the stopped process M\u03c4 = (Mt\u2227\u03c4)t\u22650 is again a martingale (because we have E[Mt\u03c4 |Fs] = Ms\u03c4); if M is an RC martingale and \u03c4 is any stopping time, then we always have for any t > 0 that E[M\u03c4\u2227t] = E[M0], and if \u03c4 is bounded or M is uniformly integrable, then we also obtain E[M\u03c4] = E[M0]. The conditions of the Stopping Theorem are necessary: consider a Brownian motion W and the stopping time \u03c4 := inf{t > 0 : Wt > 1}; due to the law of the iterated logarithm, we have \u03c4 < \u221e P-a.s., and since W has continuous trajectories, we obtain W\u03c4 = 1 P-a.s.; for \u03c3 = 0, if the theorem were valid for W and \u03c4, \u03c3, we should obtain, taking expectations, that 1 = E[W\u03c4] = E[W\u03c3] = E[W0] = 0, which is clearly false.",
        "An adapted process X = (Xt)t\u22650 null at 0 (i.e., with X0 = 0) is called a local martingale null at 0 (with respect to P and IF) if there exists a sequence of stopping times (\u03c4n)n\u2208\u2115 increasing to \u221e such that for each n \u2208 \u2115, the stopped process X\u03c4n = (Xt\u2227\u03c4n)t\u22650 is a (P, IF)-martingale, and (\u03c4n)n\u2208\u2115 is then called a localising sequence.",
        "Given a (P, IF)-Brownian motion W = (Wt)t\u22650, the following processes are (P, IF)-martingales: W itself, W\u00b2 - t for t \u2265 0, and e\u03b1Wt - (\u03b1^2)t/2 for t \u2265 0 and any \u03b1 \u2208 \u211d. These processes satisfy the martingale property E[Mt | Fs] = Ms, which is shown using the properties of Brownian motion and its normal distribution.",
        "A useful application of the martingale results is the calculation of Laplace transforms of certain stopping times: let W = (Wt)t\u22650 be a Brownian motion and define for a > 0, b > 0 the stopping times \u03c4a := inf{t \u2265 0 : Wt > a} and \u03c3a,b := inf{t \u2265 0 : Wt > a + bt}; then, for any \u03bb > 0, we have E[e^(-\u03bb\u03c4a)] = e^(-a\u221a(2\u03bb)) and E[e^(-\u03bb\u03c3a,b)] = E[e^(-\u03bb\u03c3a,b)I{\u03c3a,b<\u221e}] = e^(-a(b+\u221a(b\u00b2+2\u03bb))). For a general random variable U > 0, the function \u03bb \u2192 E[e^(-\u03bbU)] for \u03bb > 0 is called the Laplace transform of U, and its general importance in probability theory is that it uniquely determines the distribution of U; both \u03c4a and \u03c3a,b arise in connection with various exotic options in mathematical finance, particularly for barrier options, whose payoff depends on whether a (upper or lower) level has been hit or not at some given time."
      ]
    },
    {
      "topic": "Markovian Properties",
      "sub_topics": [
        "For a Brownian motion (Wt)t\u22650 and any fixed time T \u2208 (0, \u221e), the process Wt+T - WT, t \u2265 0, is again a Brownian motion, implying that restarting a Brownian motion from level 0 at some fixed time results in a process that behaves as if it had only just started; the increments Wt+T - WT, t \u2265 0, are independent of FT, where FT = \u03c3(Ws, s \u2264 T) is the \u03c3-field generated by BM up to time T, meaning that BM at any fixed time T simply forgets its past up to time T (with the only possible exception that it remembers its current position WT at time T) and starts afresh.",
        "The Markov property of Brownian motion states that for functions g \u2265 0 applied to the part of BM after time T, E[g(Wu, u \u2265 T) | \u03c3(Ws, s \u2264 T)] = E[g(Wu, u \u2265 T) | \u03c3(WT)], indicating that the behavior of W after time T depends only on the current value WT and not on the past. If we are interested in the behavior of W after time T and try to predict this based on the past of W up to time T, we may as well forget the past and look only at the current value WT at time T.",
        "The Markov property of BM can be interesting and useful if we replace the fixed time T \u2208 (0, \u221e) by a stopping time \u03c4; however, it is not clear whether this would be true, as \u03c4 itself may depend explicitly on the past behavior of BM; however, BM is said to have the strong Markov property. A precise analogue of the Markov property for a stopping time becomes a bit technical: if we denote almost as above by IFW the filtration generated by W (and made right-continuous, to be precise), and if \u03c4 is a stopping time with respect to IFW and such that \u03c4 < \u221e P-a.s., then Wt+\u03c4 - W\u03c4, t\u22650, is again a BM and independent of F\u03c4W, which includes the previous properties as special cases."
      ]
    }
  ]
}